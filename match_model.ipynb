{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00547978-0890-4b47-bb06-3458c9aaa647",
   "metadata": {},
   "source": [
    "# <font color='brown'>Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d030103-6aff-4404-af0d-8159b4c0fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 993 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report, log_loss, brier_score_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198edf27-66a3-4c2c-a1e7-68e86a6bac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\Documents\\\\GitHub\\\\Classification_datascience\\\\webscrapping\\\\matches\\\\rounds\\\\'\n",
    "df = pd.read_csv('{}matches_csv.csv'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a5d109-d380-4137-96fe-c37d3b6e6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"AtkScore\", \"DefScore\", \"ATK_Bank\", \"DEF_Bank\", \"FinalWinner\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2adda0a-d096-4fe4-9e09-a835caa4dc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtkScore</th>\n",
       "      <th>DefScore</th>\n",
       "      <th>ATK_Bank</th>\n",
       "      <th>DEF_Bank</th>\n",
       "      <th>FinalWinner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8800</td>\n",
       "      <td>2800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>14500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9200</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3400</td>\n",
       "      <td>19300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtkScore  DefScore  ATK_Bank  DEF_Bank  FinalWinner\n",
       "0         0         1       300       100            1\n",
       "1         0         2      8800      2800            1\n",
       "2         0         3       900     14500            1\n",
       "3         0         4      9200     11000            1\n",
       "4         1         4      3400     19300            1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa284140-e06e-4308-b9b3-c8bf95ead77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['FinalWinner'], axis='columns')\n",
    "Y = df.FinalWinner\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e750d756-af37-4aee-b3b2-abbb0441d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_train=lgb.Dataset(X_train, label=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43e744c9-5813-4ec1-b081-6ca4e4b1adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MatchReplay:\n",
    "    def __init__(self, match_id: int, input_df: pd.DataFrame, **kwargs):\n",
    "        self.df: pd.DataFrame = input_df\n",
    "        self.match_id: int = match_id\n",
    "        self.query: pd.DataFrame = input_df.query('MatchID == {}'.format(match_id))\n",
    "        self.half = False\n",
    "        if 'half' in kwargs and kwargs['half']:\n",
    "            self.half = True\n",
    "\n",
    "    def get_round_table(self) -> dict:\n",
    "        g = self.query[[\"RoundNumber\", \"RoundID\"]]\n",
    "        g.drop_duplicates()\n",
    "        return dict(zip(g.RoundNumber, g.RoundID))\n",
    "\n",
    "    def get_atk_scores(self, **kwargs) -> List[int]:\n",
    "        dfm = list(self.get_round_winners().values())\n",
    "        score_dict = {'atk': 0, 'def': 0}\n",
    "        atk_scores = []\n",
    "\n",
    "        slice_index = 12\n",
    "\n",
    "        if self.half:\n",
    "            slice_index = 6\n",
    "\n",
    "        for i in dfm[:slice_index]:\n",
    "            if i == 1:\n",
    "                score_dict['atk'] += 1\n",
    "            atk_scores.append(score_dict['atk'])\n",
    "        for j in dfm[slice_index:slice_index*2]:\n",
    "            if j == 0:\n",
    "                score_dict['atk'] += 1\n",
    "            atk_scores.append(score_dict['atk'])\n",
    "\n",
    "        return atk_scores\n",
    "\n",
    "    def get_def_scores(self, **kwargs) -> List[int]:\n",
    "        dfm = list(self.get_round_winners().values())\n",
    "        score_dict = {'atk': 0, 'def': 0}\n",
    "        def_scores = []\n",
    "\n",
    "        slice_index = 12\n",
    "\n",
    "        if self.half:\n",
    "            slice_index = 6\n",
    "\n",
    "        for i in dfm[:slice_index]:\n",
    "            if i == 0:\n",
    "                score_dict['def'] += 1\n",
    "            def_scores.append(score_dict['def'])\n",
    "        for j in dfm[slice_index:slice_index*2]:\n",
    "            if j == 1:\n",
    "                score_dict['def'] += 1\n",
    "            def_scores.append(score_dict['def'])\n",
    "\n",
    "        return def_scores\n",
    "\n",
    "    def get_round_winners(self) -> dict:\n",
    "        g = self.query[[\"RoundNumber\", \"FinalWinner\"]]\n",
    "        g.drop_duplicates()\n",
    "        return dict(zip(g.RoundNumber, g.FinalWinner))\n",
    "\n",
    "    def get_match_winner(self) -> int:\n",
    "        winner = 0\n",
    "        atks = self.get_atk_scores()\n",
    "        defs = self.get_def_scores()\n",
    "\n",
    "        if self.half:\n",
    "            half_dict = {'atk': atks[-1], 'def': defs[-1]}\n",
    "            if half_dict['atk'] and half_dict['def'] == 6:\n",
    "                winner = 2\n",
    "            max_score = max(half_dict, key=half_dict.get)\n",
    "            if max_score == 'atk':\n",
    "                winner = 1\n",
    "            elif max_score == 'def':\n",
    "                winner = 0\n",
    "        elif atks[-1] == 12 and defs[-1] == 12:\n",
    "            winner = 2\n",
    "        elif atks[-1] == 13:\n",
    "            winner = 1\n",
    "        elif defs[-1] == 13:\n",
    "            winner = 0\n",
    "\n",
    "        return winner\n",
    "\n",
    "    def generate_match_dataframe(self) -> pd.DataFrame:\n",
    "        r_number = pd.Series(self.get_round_table().keys())\n",
    "        r_atk = pd.Series(self.get_atk_scores())\n",
    "        r_def = pd.Series(self.get_def_scores())\n",
    "        r_winner = pd.Series([self.get_match_winner()] * len(r_number))\n",
    "        r_ids = pd.Series([self.match_id] * len(r_number))\n",
    "        r_atk_bank = pd.Series(self.get_atk_bank())\n",
    "        r_def_bank = pd.Series(self.get_def_bank())\n",
    "\n",
    "        frame = {'MatchID': r_ids, 'RoundNumber': r_number, 'AtkScore': r_atk, 'DefScore': r_def,\n",
    "                 'ATK_Bank': r_atk_bank, 'DEF_Bank': r_def_bank,\n",
    "                 'FinalWinner': r_winner}\n",
    "\n",
    "        d_frame = pd.DataFrame(frame)\n",
    "        d_frame.dropna()\n",
    "\n",
    "        return d_frame\n",
    "\n",
    "    def get_all_matches(self) -> set:\n",
    "        return set(self.df.MatchID)\n",
    "\n",
    "    def get_atk_bank(self) -> List[int]:\n",
    "        return [\n",
    "            max(self.query.query('RoundNumber == {}'.format(r)).ATK_bank)\n",
    "            for r in self.get_round_table().keys()\n",
    "        ]\n",
    "\n",
    "    def get_def_bank(self) -> List[int]:\n",
    "        return [\n",
    "            max(self.query.query('RoundNumber == {}'.format(r)).DEF_bank)\n",
    "            for r in self.get_round_table().keys()\n",
    "        ]\n",
    "\n",
    "    def get_big_dataframe(self):\n",
    "        df_list = []\n",
    "        match_indexes = list(self.get_all_matches())\n",
    "\n",
    "        for i in match_indexes:\n",
    "            self.match_id = i\n",
    "            print(i)\n",
    "            self.query: pd.DataFrame = self.df.query('MatchID == {}'.format(i))\n",
    "            df_list.append(self.generate_match_dataframe())\n",
    "\n",
    "        merged = pd.concat(df_list)\n",
    "        merged.dropna(inplace=True)\n",
    "        merged[\"AtkScore\"] = merged[\"AtkScore\"].astype(int)\n",
    "        merged[\"DefScore\"] = merged[\"DefScore\"].astype(int)\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def export_big_dataframe(self):\n",
    "        big_df = self.get_big_dataframe()\n",
    "        big_df.to_csv(r'matches\\rounds\\matches_csv.csv', index=False)\n",
    "        print('SUCCESS!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97dbe6a9-bffb-4121-8b87-cf564244cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = 26508\n",
    "path2 = 'D:\\\\Documents\\\\GitHub\\\\Classification_datascience\\\\webscrapping\\\\matches\\\\rounds\\\\combined_csv.csv'\n",
    "data = pd.read_csv('{}'.format(path2))\n",
    "\n",
    "mr = MatchReplay(match, data, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30f0adfc-da9a-4f5d-b8d6-281be5c6b673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 1, 2, 3, 4, 4]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.get_def_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf4922-0a37-46e4-a4c3-9c982ac7124b",
   "metadata": {},
   "source": [
    "# <font color='brown'>Model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a4412dd-216c-462a-a536-a89dd8f15906",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-71c6a81f39dd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msvm_model_linear\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSVC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkernel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'linear'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68d7f6-fb5c-4cca-8731-9d1f392dabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "accuracy = svm_model_linear.score(X_test, Y_test)\n",
    "cm = confusion_matrix(Y_test, svm_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac993038-7bcf-4972-8bb2-9814342eaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "cm = (cm/cm.sum(axis=1).reshape(-1,1))\n",
    "\n",
    "sns.heatmap(cm, cmap=\"YlGnBu\", vmin=0., vmax=1., annot=True, annot_kws={'size':45})\n",
    "plt.title(\"wa\", fontsize = 5)\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xlabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70344386-2c29-4051-a09c-557d836a60eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3fc7a4-a4e2-4b18-83c7-e5e338a8f550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f79b6a-f0bc-4a92-972f-9f1acdd92ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "862a01ca-81c2-40f5-9fbc-1bd3d268657e",
   "metadata": {},
   "source": [
    "# <font color='brown'>Metrics </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "535bb69a-ef6e-4737-967f-4e79e2f6b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pruned = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "clf_pruned.fit(X_train, Y_train)\n",
    "Y_pred = clf_pruned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "991d6cbd-0313-4aed-9ee1-ee145a490411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.64      0.87      0.74      2549\n",
      "     class 1       0.71      0.66      0.68      2327\n",
      "     class 2       0.00      0.00      0.00       733\n",
      "\n",
      "    accuracy                           0.67      5609\n",
      "   macro avg       0.45      0.51      0.47      5609\n",
      "weighted avg       0.59      0.67      0.62      5609\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\mateu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(Y_test, Y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ab114-4cc5-4b6a-910e-2832a87e4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "cm = (cm/cm.sum(axis=1).reshape(-1,1))\n",
    "\n",
    "sns.heatmap(cm, cmap=\"YlGnBu\", vmin=0., vmax=1., annot=True, annot_kws={'size':45})\n",
    "plt.title(\"wa\", fontsize = 5)\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xlabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9440ed3-9697-4d69-ac07-80625a3753b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba7bb1fb-2cc2-42e2-a8b0-e85e46e7fbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtkScore</th>\n",
       "      <th>DefScore</th>\n",
       "      <th>ATK_Bank</th>\n",
       "      <th>DEF_Bank</th>\n",
       "      <th>FinalWinner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8800</td>\n",
       "      <td>5200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1700</td>\n",
       "      <td>15300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9900</td>\n",
       "      <td>27900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3600</td>\n",
       "      <td>27700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27710</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3900</td>\n",
       "      <td>39800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27711</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2600</td>\n",
       "      <td>35100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27712</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2900</td>\n",
       "      <td>17300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27713</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>8000</td>\n",
       "      <td>24500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27714</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>900</td>\n",
       "      <td>30300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3456 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AtkScore  DefScore  ATK_Bank  DEF_Bank  FinalWinner\n",
       "78            0         1       100         0            2\n",
       "79            0         2      8800      5200            2\n",
       "80            0         3      1700     15300            2\n",
       "81            0         4      9900     27900            2\n",
       "82            1         4      3600     27700            2\n",
       "...         ...       ...       ...       ...          ...\n",
       "27710        10        10      3900     39800            2\n",
       "27711        10        11      2600     35100            2\n",
       "27712        11        11      2900     17300            2\n",
       "27713        12        11      8000     24500            2\n",
       "27714        12        12       900     30300            2\n",
       "\n",
       "[3456 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('FinalWinner == {}'.format(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b128bbb4-1fa0-4172-b641-6bbd1ffa609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of numbers from 1 to 10\n",
    "l1 = list(range(1, 15))\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}